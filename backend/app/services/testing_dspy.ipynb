{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3411eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "import json\n",
    "from typing import Literal\n",
    "import uuid\n",
    "import datetime\n",
    "from typing import Optional\n",
    "from langsmith import Client\n",
    "from dotenv import load_dotenv\n",
    "from app.services.dspy_optimizer import DspyOptimizer\n",
    "from app.websocket.manager import connection_manager\n",
    "from app.db.database import get_db, init_db\n",
    "from app.models.item import ItemInDB\n",
    "from app.models.node import NodeInDB\n",
    "from bson import ObjectId\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01d37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangSmithCallback:\n",
    "    \"\"\"Callback class to trace DSPy LLM calls with LangSmith\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, project_name: str = \"dspy-tracing\", client: Optional[Client] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the LangSmith callback\n",
    "\n",
    "        Args:\n",
    "            project_name: Name of the LangSmith project\n",
    "            client: Optional LangSmith client instance\n",
    "        \"\"\"\n",
    "        self.client = client or Client()\n",
    "        self.project_name = project_name\n",
    "        self.run_stack = []  # Stack to handle nested calls\n",
    "        self.current_module_run = None\n",
    "        self.current_lm_run = None\n",
    "\n",
    "    def on_module_start(self, call_id, **kwargs):\n",
    "        \"\"\"Called when a DSPy module starts execution\"\"\"\n",
    "        # Extract expected arguments from kwargs\n",
    "        module = kwargs.get('module') or kwargs.get('instance')\n",
    "        inputs = kwargs.get('inputs', {})\n",
    "        \n",
    "        run_id = str(uuid.uuid4())\n",
    "        start_time = datetime.datetime.now(datetime.UTC)\n",
    "        \n",
    "        # Get module name\n",
    "        module_name = \"Unknown\"\n",
    "        if module:\n",
    "            module_name = module.__class__.__name__ if hasattr(module, '__class__') else str(module)\n",
    "        \n",
    "        run_info = {\n",
    "            \"id\": run_id,\n",
    "            \"start_time\": start_time,\n",
    "            \"type\": \"module\",\n",
    "            \"module_name\": module_name,\n",
    "        }\n",
    "        \n",
    "        self.run_stack.append(run_info)\n",
    "        self.current_module_run = run_info\n",
    "        \n",
    "        # Create the run in LangSmith\n",
    "        self.client.create_run(\n",
    "            id=run_id,\n",
    "            project_name=self.project_name,\n",
    "            name=f\"dspy_{module_name}\",\n",
    "            run_type=\"chain\",\n",
    "            inputs={\"inputs\": str(inputs), **kwargs},\n",
    "            start_time=start_time,\n",
    "            parent_run_id=self.run_stack[-2][\"id\"] if len(self.run_stack) > 1 else None,\n",
    "        )\n",
    "\n",
    "    def on_module_end(self, call_id, **kwargs):\n",
    "        \"\"\"Called when a DSPy module ends execution\"\"\"\n",
    "        if not self.run_stack:\n",
    "            return\n",
    "            \n",
    "        run_info = self.run_stack.pop()\n",
    "        end_time = datetime.datetime.now(datetime.UTC)\n",
    "        # Extract outputs and handle exceptions\n",
    "        outputs = kwargs.get('outputs', kwargs.get('results', {}))\n",
    "        exception = kwargs.get('exception')\n",
    "        \n",
    "        output_data = {\n",
    "            \"outputs\": str(outputs) if outputs else None,\n",
    "        }\n",
    "        \n",
    "        # Include exception info if present\n",
    "        if exception:\n",
    "            output_data[\"error\"] = str(exception)\n",
    "        \n",
    "        # Update the run with outputs\n",
    "        self.client.update_run(\n",
    "            run_id=run_info[\"id\"],\n",
    "            outputs=output_data,\n",
    "            end_time=end_time,\n",
    "            error=str(exception) if exception else None,\n",
    "        )\n",
    "        \n",
    "        # Update current module run\n",
    "        self.current_module_run = self.run_stack[-1] if self.run_stack else None\n",
    "\n",
    "    def on_lm_start(self, call_id, **kwargs):\n",
    "        \"\"\"Called when an LM call starts\"\"\"\n",
    "        # Extract expected arguments from kwargs\n",
    "        model_name = kwargs.get('model_name', kwargs.get('model', 'unknown'))\n",
    "        prompt = kwargs.get('prompt', kwargs.get('messages', ''))\n",
    "        temperature = kwargs.get('temperature')\n",
    "        max_tokens = kwargs.get('max_tokens')\n",
    "        \n",
    "        run_id = str(uuid.uuid4())\n",
    "        start_time = datetime.datetime.now(datetime.UTC)\n",
    "        \n",
    "        run_info = {\n",
    "            \"id\": run_id,\n",
    "            \"start_time\": start_time,\n",
    "            \"type\": \"lm\",\n",
    "            \"model\": model_name,\n",
    "        }\n",
    "        \n",
    "        self.current_lm_run = run_info\n",
    "        \n",
    "        # Create run inputs\n",
    "        inputs = {\n",
    "            \"prompt\": str(prompt),\n",
    "            \"model\": model_name,\n",
    "        }\n",
    "        \n",
    "        if temperature is not None:\n",
    "            inputs[\"temperature\"] = temperature\n",
    "        if max_tokens is not None:\n",
    "            inputs[\"max_tokens\"] = max_tokens\n",
    "            \n",
    "        # Add any additional kwargs\n",
    "        for k, v in kwargs.items():\n",
    "            if k not in ['call_id', 'model_name', 'prompt', 'temperature', 'max_tokens']:\n",
    "                inputs[k] = v\n",
    "        \n",
    "        # Create the run in LangSmith\n",
    "        self.client.create_run(\n",
    "            id=run_id,\n",
    "            project_name=self.project_name,\n",
    "            name=\"dspy_lm_call\",\n",
    "            run_type=\"llm\",\n",
    "            inputs=inputs,\n",
    "            start_time=start_time,\n",
    "            parent_run_id=self.current_module_run[\"id\"] if self.current_module_run else None,\n",
    "        )\n",
    "\n",
    "    def on_lm_end(self, call_id, **kwargs):\n",
    "        \"\"\"Called when an LM call ends\"\"\"\n",
    "        if not self.current_lm_run:\n",
    "            return\n",
    "            \n",
    "        end_time = datetime.datetime.now(datetime.UTC)\n",
    "        \n",
    "        # Extract response and usage from kwargs\n",
    "        response = kwargs.get('response', kwargs.get('outputs', kwargs.get('completions', '')))\n",
    "        usage = kwargs.get('usage')\n",
    "        \n",
    "        outputs = {\n",
    "            \"response\": str(response) if response else None,\n",
    "        }\n",
    "        \n",
    "        if usage:\n",
    "            outputs[\"usage\"] = usage\n",
    "            \n",
    "        # Add any additional kwargs\n",
    "        for k, v in kwargs.items():\n",
    "            if k not in ['call_id', 'response', 'outputs', 'completions', 'usage']:\n",
    "                outputs[k] = v\n",
    "        \n",
    "        # Update the run with outputs\n",
    "        self.client.update_run(\n",
    "            run_id=self.current_lm_run[\"id\"],\n",
    "            outputs=outputs,\n",
    "            end_time=end_time,\n",
    "        )\n",
    "        \n",
    "        self.current_lm_run = None\n",
    "\n",
    "    def on_adapter_format_start(self, call_id, **kwargs):\n",
    "        \"\"\"Called when adapter formatting starts\"\"\"\n",
    "        # For now, we'll just log this as metadata\n",
    "        pass\n",
    "\n",
    "    def on_adapter_format_end(self, call_id, **kwargs):\n",
    "        \"\"\"Called when adapter formatting ends\"\"\"\n",
    "        # For now, we'll just log this as metadata\n",
    "        pass\n",
    "\n",
    "    def on_adapter_parse_start(self, call_id, **kwargs):\n",
    "        \"\"\"Called when adapter parsing starts\"\"\"\n",
    "        # For now, we'll just log this as metadata\n",
    "        pass\n",
    "\n",
    "    def on_adapter_parse_end(self, call_id, **kwargs):\n",
    "        \"\"\"Called when adapter parsing ends\"\"\"\n",
    "        # For now, we'll just log this as metadata\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662aead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database indexes created\n",
      "Connected to MongoDB\n",
      "item_ids_to_optimize: 7\n",
      "trainset: 7\n"
     ]
    }
   ],
   "source": [
    "await init_db()\n",
    "db = get_db()\n",
    "\n",
    "request = {\n",
    "    \"taxonomy_id\": \"68913c1c1c58af74cb5d53b8\",  # customer feedback\n",
    "    \"node_id\": \"68913c501c58af74cb5d53b9\",  # Product Quality Issues\n",
    "    \"current_user\": \"688a2f73d286129d6167cc93\", # bonsense\n",
    "}\n",
    "\n",
    "nodes_collection = db[f\"nodes_{request['taxonomy_id']}\"]\n",
    "node = await nodes_collection.find_one({\"_id\": ObjectId(request[\"node_id\"])})\n",
    "if not node:\n",
    "    raise ValueError(\"Node not found\")\n",
    "\n",
    "node = NodeInDB(**node)\n",
    "\n",
    "items = node.items\n",
    "if items is None:\n",
    "    raise ValueError(\"Node has no items\")\n",
    "\n",
    "item_ids_to_optimize = [\n",
    "    ObjectId(item.item_id) for item in items if item.is_verified\n",
    "]\n",
    "print(f\"item_ids_to_optimize: {len(item_ids_to_optimize)}\")\n",
    "if len(item_ids_to_optimize) < 1:\n",
    "    raise ValueError(\n",
    "        f\"Need at least 10 verified items and found {len(item_ids_to_optimize)}\"\n",
    "    )\n",
    "\n",
    "user_items_collection = db[f\"items_{str(request['current_user'])}\"]\n",
    "items_to_optimize = await user_items_collection.find(\n",
    "    {\"_id\": {\"$in\": item_ids_to_optimize}}\n",
    ").to_list(length=None)\n",
    "items_to_optimize = [ItemInDB(**item) for item in items_to_optimize]\n",
    "\n",
    "trainset = []\n",
    "for item in items_to_optimize:\n",
    "    trainset.append(\n",
    "        dspy.Example(review=item.content, category=node.label).with_inputs(\"review\")\n",
    "    )\n",
    "\n",
    "sibling_nodes = await nodes_collection.find(\n",
    "    {\"parent_node_id\": node.parent_node_id}\n",
    ").to_list(length=None)\n",
    "sibling_nodes = [NodeInDB(**sibling_node) for sibling_node in sibling_nodes]\n",
    "categories_labels = [sibling_node.label for sibling_node in sibling_nodes] + [\n",
    "    node.label\n",
    "]\n",
    "print(f\"{len(categories_labels)} categories_labels: {categories_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19956d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy_optimizer = DspyOptimizer(\n",
    "    lm=dspy.LM(\"openai/gpt-4.1-nano-2025-04-14\"),\n",
    "    connection_manager=connection_manager,\n",
    "    user_id=str(request[\"current_user\"]),\n",
    "    categories=categories_labels,\n",
    "    trainset=trainset,\n",
    "    callbacks=[LangSmithCallback(project_name=\"dspy-test\")],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_id = await dspy_optimizer.compile()\n",
    "print(module_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7b38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    category='Service & Delivery Experience'\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# module_id = \"\"\n",
    "await dspy_optimizer.predict(\n",
    "    review=\"I am a happy person\",\n",
    "    compiled_module_id=module_id,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
